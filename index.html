<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Bilateral Denoising Diffusion Models</title>
      <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
      <link rel="stylesheet"
href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
      <!-- <link rel="shortcut icon" href="../../images/taco.png"> -->
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      extensions: ["tex2jax.js"],
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], scale: 77},
      tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
      TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "50%" } } },
      messageStyle: "none"
    });
    </script>    
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"></script>
      <script>
         function play(path) {{
           var player = document.getElementById('player');
           player.src = path;
           player.play();
         }}
         function isInternetExplorer() {
            ua = navigator.userAgent;
            /* MSIE used to detect old browsers and Trident used to newer ones*/
            return ua.indexOf("MSIE ") > -1 || ua.indexOf("Trident/") > -1;
          }

          /* Define the Animation class */
          function Animation(frames, img_id, slider_id, interval, loop_select_id){
            this.img_id = img_id;
            this.slider_id = slider_id;
            this.loop_select_id = loop_select_id;
            this.interval = interval;
            this.current_frame = 0;
            this.direction = 0;
            this.timer = null;
            this.frames = new Array(frames.length);

            for (var i=0; i<frames.length; i++)
            {
             this.frames[i] = new Image();
             this.frames[i].src = frames[i];
            }
            var slider = document.getElementById(this.slider_id);
            slider.max = this.frames.length - 1;
            if (isInternetExplorer()) {
                // switch from oninput to onchange because IE <= 11 does not conform
                // with W3C specification. It ignores oninput and onchange behaves
                // like oninput. In contrast, Mircosoft Edge behaves correctly.
                slider.setAttribute('onchange', slider.getAttribute('oninput'));
                slider.setAttribute('oninput', null);
            }
            this.set_frame(this.current_frame);
          }

          Animation.prototype.get_loop_state = function(){
            return 0;
          }

          Animation.prototype.set_frame = function(frame){
            this.current_frame = frame;
            document.getElementById(this.img_id).src =
                    this.frames[this.current_frame].src;
            document.getElementById(this.slider_id).value = this.current_frame;
          }

          Animation.prototype.next_frame = function()
          {
            this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));
          }

          Animation.prototype.previous_frame = function()
          {
            this.set_frame(Math.max(0, this.current_frame - 1));
          }

          Animation.prototype.first_frame = function()
          {
            this.set_frame(0);
          }

          Animation.prototype.last_frame = function()
          {
            this.set_frame(this.frames.length - 1);
          }

          Animation.prototype.slower = function()
          {
            this.interval /= 0.7;
            if(this.direction > 0){this.play_animation();}
            else if(this.direction < 0){this.reverse_animation();}
          }

          Animation.prototype.faster = function()
          {
            this.interval *= 0.7;
            if(this.direction > 0){this.play_animation();}
            else if(this.direction < 0){this.reverse_animation();}
          }

          Animation.prototype.anim_step_forward = function()
          {
            this.current_frame += 1;
            if(this.current_frame < this.frames.length){
              this.set_frame(this.current_frame);
            }else{
              var loop_state = this.get_loop_state();
              if(loop_state == "loop"){
                this.first_frame();
              }else if(loop_state == "reflect"){
                this.last_frame();
                this.reverse_animation();
              }else{
                this.pause_animation();
                this.last_frame();
              }
            }
          }

          Animation.prototype.anim_step_reverse = function()
          {
            this.current_frame -= 1;
            if(this.current_frame >= 0){
              this.set_frame(this.current_frame);
            }else{
              var loop_state = this.get_loop_state();
              if(loop_state == "loop"){
                this.last_frame();
              }else if(loop_state == "reflect"){
                this.first_frame();
                this.play_animation();
              }else{
                this.pause_animation();
                this.first_frame();
              }
            }
          }

          Animation.prototype.pause_animation = function()
          {
            this.direction = 0;
            if (this.timer){
              clearInterval(this.timer);
              this.timer = null;
            }
          }

          Animation.prototype.play_animation = function()
          {
            this.pause_animation();
            this.direction = 1;
            var t = this;
            if (!this.timer) this.timer = setInterval(function() {
                t.anim_step_forward();
            }, this.interval);
          }

          Animation.prototype.reverse_animation = function()
          {
            this.pause_animation();
            this.direction = -1;
            var t = this;
            if (!this.timer) this.timer = setInterval(function() {
                t.anim_step_reverse();
            }, this.interval);
          }
      </script>
      <style>
          .animation {
              display: inline-block;
              text-align: center;
          }
          input[type=range].anim-slider {
              width: 374px;
              margin-left: auto;
              margin-right: auto;
          }
          .anim-buttons {
              margin: 8px 0px;
          }
          .anim-buttons button {
              padding: 0;
              width: 36px;
          }
          .anim-state label {
              margin-right: 8px;
          }
          .anim-state input {
              margin: 0;
              vertical-align: middle;
          }
         .audio-cell {
         /* Center audio widgets in the table cell. */
         text-align: center;
         padding-bottom: 1px;
         padding-top: 1px;
         }
         .audio-cell-padded {
         text-align: center;
         padding-bottom: 10px;
         padding-top: 10px;
         }
         .audio-header {
         /* Don't wrap header text. */
         white-space: nowrap;
         /* Some breaking space between headers for readability. */
         padding-right: 5px;
         padding-left: 5px;
         }
         .reference-cell {
         /* For uniformity and to wrap long reference text, limit the reference cell's width. */
         width: 25%;
         padding-top: 20px;
         padding-bottom: 20px;
         }
         .sample audio {
         vertical-align: middle;
         padding-left: 3px;
         padding-right: 3px;
         }
         .round-button {
         box-sizing: border-box;
         display:block;
         width:30px;
         height:30px;
         padding-top: 8px;
         padding-left: 3px;
         line-height: 6px;
         border: 1.2px solid #000;
         border-radius: 50%;
         color: #000;
         text-align:center;
         background-color: rgba(0,0,0,0.00);
         font-size:6px;
         box-shadow: 0px 0px 2px rgba(0,0,0,1);
         transition: all 0.2s ease;
         }
         .round-button:hover {
         background-color: rgba(0,0,0,0.0);
         box-shadow: 0px 0px 4px rgba(0,0,0,1);
         }
         .round-button:active {
         background-color: rgba(0,0,0,0.01);
         box-shadow: 0px 0px 1px rgba(0,0,0,1);
         }
      </style>
   </head>
   <body>
     <div class="main">
       <article>
         <header>
            <h1>BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis</h1>
         </header>
      </article>
      <div align="justify">
      <blockquote>
      <p><b>Abstract:</b> Diffusion probabilistic models (DPMs) and their extensions have emerged as competitive generative models yet confront challenges of efficient sampling. We propose a new bilateral denoising diffusion model (BDDM) that parameterizes both the forward and reverse processes with a scheduling network and a score network, which can train with a novel bilateral modeling objective. We show that the new surrogate objective can achieve a lower bound of the log marginal likelihood tighter than a conventional surrogate. We also find that BDDM allows inheriting pre-trained score network parameters from any DPMs and consequently enables speedy and stable learning of the scheduling network and optimization of a noise schedule for sampling. Our experiments demonstrate that BDDMs can generate high-fidelity audio samples with as few as 3 sampling steps. Moreover, comparing to other state-of-the-art diffusion-based neural vocoders, BDDMs produce comparable or higher quality samples indistinguishable from human speech, notably with only 7 sampling steps (143x faster than WaveGrad and 28.6x faster than DiffWave).
      </p>
      </blockquote>
      <!-- <h3>
        Comparing BDDM with the standard ELBO objectives:
      </h3>
      <table>
        <tbody>
          <tr>
            <td width="40%" align="justify" valign="top">
               <img src="imgs/step_loss.png" width="90%" style="padding-top:3%;">
               <br/>
            </td>
            <td width="40%" align="justify" valign="top" style="padding-top:1%;">
               <img src="imgs/bounds.png" width="100%">
               <br/>
            </td>
          </tr>
        </tbody>
      </table>
      <table>
        <tbody>
          <tr>
            <td width="50%" align="justify" valign="top" style="padding-left: 5%;padding-right: 5%;">
               The above diagram compares the scheduling networks' outputs when training with $\mathcal{L}^{(t)}_\text{step}$ and $\mathcal{L}^{(t)}_\text{elbo}$, respectively. The plot shows that when using $\mathcal{L}^{(t)}_\text{elbo}$ to learn $\phi$, the network output rapidly collapsed to zero within several training steps; whereas, the network trained with $\mathcal{L}^{(t)}_\text{step}$ produced outputs fluctuating around 1. The fluctuation is a desirable property indicating that the network can predict a $t$-dependent noise scale, where $t$ is a random time step drawn from an uniform distribution.
            </td>
            <td width="50%" align="justify" valign="top" style="padding-left: 8%;padding-right: 2%;">
                The above diagram shows the result of another experiment that validates the inequality of lower bounds: $\mathcal{F}^{(t)}_\text{bddm} \geq \mathcal{F}^{(t)}_\text{elbo}(\theta^*)$ for different time step $t$. We dropped their common entropy term $\mathbb{E}\left[\log p_\theta(\mathbf{x}_0|\mathbf{x}_1)\right] < 0$ to mainly compare the KL terms. Therefore, the plotted lower bound values might be positive. Each value is provided with 95% confidence intervals.
            </td>
          </tr>
        </tbody>
      </table> -->
      <h3>
        Fast and high-fidelity speech generation using BDDMs:
      </h3>
      <p>
        By introducing a scheduling network optimized with our derived loss, we can generate high-fidelity speech with as few as 3 steps.
         <!-- style="background-color: #FFFF00" -->
      </p>
      <p>
      <blockquote><p><b>Text:</b>
      Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition.</p></blockquote>
      </p>
      <!-- WaveGrad outputs with <i>6 refinement steps:</i>      -->
      <p style="color:red;"><b></b></p>
      <table>
        <tbody>
          <tr>
            <td nowrap><b>Step 0 (White Noise):</b> </td><td style="text-align:center" nowrap> Note: Consider lower volume before listening</td>
          </tr>
          <tr>
            <td class="text_e2e">
               <audio controls="">
                  <source src="wavs/rand.wav">
               </audio>
            </td>
            <td>
               <img src="imgs/noise_spec.png">
            </td>
          </tr>
          <tr>
            <td nowrap><b>Step 1:</b> </td><td style="text-align:center" nowrap></td>
          </tr>
          <tr>
            <td class="text_e2e">
               <audio controls="">
                  <source src="wavs/s1.wav">
               </audio>
            </td>
            <td>
               <img src="imgs/spec1.png">
            </td>
          </tr>
          <tr>
            <td nowrap><b>Step 2:</b> </td><td style="text-align:center" nowrap></td>
          </tr>
          <tr>
            <td class="text_e2e">
               <audio controls="">
                  <source src="wavs/s2.wav">
               </audio>
            </td>
            <td>
               <img src="imgs/spec2.png">
            </td>
          </tr>
          <tr>
            <td nowrap><b>Step 3:</b> </td><td style="text-align:center" nowrap></td>
          </tr>
          <tr>
            <td class="text_e2e">
               <audio controls="">
                  <source src="wavs/s3.wav">
               </audio>
            </td>
            <td>
               <img src="imgs/spec3.png">
            </td>
          </tr>
        </tbody>
      </table>
         <h3> LJ speech samples generated from different neural vocoders:</h3>
         <p>
            <b>Note:</b>
            Different rows correspond to different noise schedules or sampling methods for inference.
         </p>
         <table>
            <tbody>
               <tr>
                  <td nowrap> Text </td>
                  <td class="text_e2e">Under the new rule visitors were not allowed to pass into the interior of the prison, but were detained between the grating.</td>
                  <td class="text_e2e">This Commission can recommend no procedures for the future protection of our Presidents which will guarantee security.</td>
               </tr>
               <tr>
                  <td nowrap class="text_method">Ground Truth</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/gt1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/gt2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">WaveNet (MoL)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/wn1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/wn2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">WaveGlow</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/glow1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/glow2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">MelGAN</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/mel1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/mel2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">HiFi-GAN V1</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/hifi1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/hifi2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">WaveGrad</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/wavegrad1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/wavegrad2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">DiffWave</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/diff1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/diff2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method"><b>BDDM - 3 steps</b></td>
                  <td>
                     <audio controls="">
                        <source src="wavs/3bddm1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/3bddm2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method"><b>BDDM - 7 steps</b></td>
                  <td>
                     <audio controls="">
                        <source src="wavs/7bddm1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/7bddm2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method"><b>BDDM - 12 steps</b></td>
                  <td>
                     <audio controls="">
                        <source src="wavs/12bddm1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/12bddm2.wav">
                     </audio>
                  </td>
               </tr>
            </tbody>
         </table>
         <h3> VCTK samples from different generative diffusion models:</h3>
         <p>
            <b>Note:</b>
            Different rows correspond to different noise schedules or sampling methods for inference.
         </p>
         <table>
            <tbody>
               <tr>
                  <td nowrap> Text </td>
                  <td class="text_e2e"><span>Frankly, we should all have such problems.</span></td>
                  <td class="text_e2e"><span>I felt he was excellent.</span></td>
               </tr>
               <tr>
                  <td nowrap class="text_method">Ground Truth</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/GT_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/GT_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">DDPM - 8 steps (Grid Search)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_8_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_8_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">DDPM - 1000 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_1000_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_1000_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">DDIM - 8 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_8_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_8_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">DDIM - 100 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_100_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_100_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method">NE - 8 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/NE_8_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/NE_8_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap class="text_method"><b>BDDM - 8 steps</b></td>
                  <td>
                     <audio controls="">
                        <source src="wavs/BDDM_8_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/BDDM_8_2.wav">
                     </audio>
                  </td>
               </tr>
            </tbody>
         </table>
         <!-- <h3> CIFAR-10 samples generated from BDDM:</h3>
         <table>
        <tbody>
          <tr>
            <td> BDDM - 10 steps </td>
            <td> BDDM - 20 steps </td>
            <td> BDDM - 100 steps </td>
          </tr>
          <tr>
            <td> <img src="imgs/BDDM10.png" width="300px"> </td>
            <td> <img src="imgs/BDDM20.png" width="300px"> </td>
            <td> <img src="imgs/BDDM100.png" width="300px"> </td>
          </tr>
        </tbody>
      </table> -->
      </div>
   </body>
</html>
