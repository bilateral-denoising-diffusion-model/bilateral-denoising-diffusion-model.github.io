<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Bilateral Denoising Diffusion Models</title>
      <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
      <link rel="stylesheet"
href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
      <!-- <link rel="shortcut icon" href="../../images/taco.png"> -->
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      extensions: ["tex2jax.js"],
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], scale: 88},
      tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
      TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "50%" } } },
      messageStyle: "none"
    });
    </script>    
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"></script>
      <script>
         function play(path) {{
           var player = document.getElementById('player');
           player.src = path;
           player.play();
         }}
         function isInternetExplorer() {
            ua = navigator.userAgent;
            /* MSIE used to detect old browsers and Trident used to newer ones*/
            return ua.indexOf("MSIE ") > -1 || ua.indexOf("Trident/") > -1;
          }

          /* Define the Animation class */
          function Animation(frames, img_id, slider_id, interval, loop_select_id){
            this.img_id = img_id;
            this.slider_id = slider_id;
            this.loop_select_id = loop_select_id;
            this.interval = interval;
            this.current_frame = 0;
            this.direction = 0;
            this.timer = null;
            this.frames = new Array(frames.length);

            for (var i=0; i<frames.length; i++)
            {
             this.frames[i] = new Image();
             this.frames[i].src = frames[i];
            }
            var slider = document.getElementById(this.slider_id);
            slider.max = this.frames.length - 1;
            if (isInternetExplorer()) {
                // switch from oninput to onchange because IE <= 11 does not conform
                // with W3C specification. It ignores oninput and onchange behaves
                // like oninput. In contrast, Mircosoft Edge behaves correctly.
                slider.setAttribute('onchange', slider.getAttribute('oninput'));
                slider.setAttribute('oninput', null);
            }
            this.set_frame(this.current_frame);
          }

          Animation.prototype.get_loop_state = function(){
            return 0;
          }

          Animation.prototype.set_frame = function(frame){
            this.current_frame = frame;
            document.getElementById(this.img_id).src =
                    this.frames[this.current_frame].src;
            document.getElementById(this.slider_id).value = this.current_frame;
          }

          Animation.prototype.next_frame = function()
          {
            this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));
          }

          Animation.prototype.previous_frame = function()
          {
            this.set_frame(Math.max(0, this.current_frame - 1));
          }

          Animation.prototype.first_frame = function()
          {
            this.set_frame(0);
          }

          Animation.prototype.last_frame = function()
          {
            this.set_frame(this.frames.length - 1);
          }

          Animation.prototype.slower = function()
          {
            this.interval /= 0.7;
            if(this.direction > 0){this.play_animation();}
            else if(this.direction < 0){this.reverse_animation();}
          }

          Animation.prototype.faster = function()
          {
            this.interval *= 0.7;
            if(this.direction > 0){this.play_animation();}
            else if(this.direction < 0){this.reverse_animation();}
          }

          Animation.prototype.anim_step_forward = function()
          {
            this.current_frame += 1;
            if(this.current_frame < this.frames.length){
              this.set_frame(this.current_frame);
            }else{
              var loop_state = this.get_loop_state();
              if(loop_state == "loop"){
                this.first_frame();
              }else if(loop_state == "reflect"){
                this.last_frame();
                this.reverse_animation();
              }else{
                this.pause_animation();
                this.last_frame();
              }
            }
          }

          Animation.prototype.anim_step_reverse = function()
          {
            this.current_frame -= 1;
            if(this.current_frame >= 0){
              this.set_frame(this.current_frame);
            }else{
              var loop_state = this.get_loop_state();
              if(loop_state == "loop"){
                this.last_frame();
              }else if(loop_state == "reflect"){
                this.first_frame();
                this.play_animation();
              }else{
                this.pause_animation();
                this.first_frame();
              }
            }
          }

          Animation.prototype.pause_animation = function()
          {
            this.direction = 0;
            if (this.timer){
              clearInterval(this.timer);
              this.timer = null;
            }
          }

          Animation.prototype.play_animation = function()
          {
            this.pause_animation();
            this.direction = 1;
            var t = this;
            if (!this.timer) this.timer = setInterval(function() {
                t.anim_step_forward();
            }, this.interval);
          }

          Animation.prototype.reverse_animation = function()
          {
            this.pause_animation();
            this.direction = -1;
            var t = this;
            if (!this.timer) this.timer = setInterval(function() {
                t.anim_step_reverse();
            }, this.interval);
          }
      </script>
      <style>
          .animation {
              display: inline-block;
              text-align: center;
          }
          input[type=range].anim-slider {
              width: 374px;
              margin-left: auto;
              margin-right: auto;
          }
          .anim-buttons {
              margin: 8px 0px;
          }
          .anim-buttons button {
              padding: 0;
              width: 36px;
          }
          .anim-state label {
              margin-right: 8px;
          }
          .anim-state input {
              margin: 0;
              vertical-align: middle;
          }
         .audio-cell {
         /* Center audio widgets in the table cell. */
         text-align: center;
         padding-bottom: 1px;
         padding-top: 1px;
         }
         .audio-cell-padded {
         text-align: center;
         padding-bottom: 10px;
         padding-top: 10px;
         }
         .audio-header {
         /* Don't wrap header text. */
         white-space: nowrap;
         /* Some breaking space between headers for readability. */
         padding-right: 5px;
         padding-left: 5px;
         }
         .reference-cell {
         /* For uniformity and to wrap long reference text, limit the reference cell's width. */
         width: 25%;
         padding-top: 20px;
         padding-bottom: 20px;
         }
         .sample audio {
         vertical-align: middle;
         padding-left: 3px;
         padding-right: 3px;
         }
         .round-button {
         box-sizing: border-box;
         display:block;
         width:30px;
         height:30px;
         padding-top: 8px;
         padding-left: 3px;
         line-height: 6px;
         border: 1.2px solid #000;
         border-radius: 50%;
         color: #000;
         text-align:center;
         background-color: rgba(0,0,0,0.00);
         font-size:6px;
         box-shadow: 0px 0px 2px rgba(0,0,0,1);
         transition: all 0.2s ease;
         }
         .round-button:hover {
         background-color: rgba(0,0,0,0.0);
         box-shadow: 0px 0px 4px rgba(0,0,0,1);
         }
         .round-button:active {
         background-color: rgba(0,0,0,0.01);
         box-shadow: 0px 0px 1px rgba(0,0,0,1);
         }
      </style>
   </head>
   <body>
     <div class="main">
       <article>
         <header>
            <h1>Bilateral Denoising Diffusion Models (BDDMs)</h1>
         </header>
      </article>
      <div align="justify">
      <p><b>Abstract:</b> Denoising diffusion models were designed with a simple forward process yet brought challenges for efficient sampling. Instead of striving for an accelerated sampler, we propose new bilateral denoising diffusion models (BDDMs) that parameterize the forward and reverse processes, with a score network and a scheduling network, respectively. From a bilateral modeling objective, we derive a tighter lower bound as a surrogate objective for the likelihood to achieve exceedingly high-quality and fast generation compared to other cutting-edge samplers. In particular, with a negligible training overhead, the proposed BDDMs generated significantly higher-quality samples with a 62x inference speed up relative to the denoising diffusion probabilistic models.
      </p>
      <h3>
        Comparing BDDM's derived objective againt the standard variational lower bound:
      </h3>
      <table>
        <tbody>
          <tr>
            <td>
               <img src="imgs/step_loss.png" width="90%">
            </td>
            <td>
               <img src="imgs/bounds.png" width="90%">
            </td>
          </tr>
          <tr></tr>
          <tr>
            The left diagram compares the scheduling networks' outputs when training with $\mathcal{L}^{(t)}_\text{step}$ and $\mathcal{L}^{(t)}_\text{elbo}:=\mathbb{KL}\left(q_\phi(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)||p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)\right)$ respectively. The plot shows that when using $\mathcal{L}^{(t)}_\text{elbo}$ to learn $\phi$, the network output rapidly collapsed to zero; whereas, the network trained with $\mathcal{L}^{(t)}_\text{step}$ produced outputs fluctuating around 1. As $t$ is randomly drawn from an uniform distribution, fluctuation means that the network is able to learn a $t$-dependent noise scale. The right diagram shows the result of another experiment that validates the inequality of lower bounds: $\log p_{\theta^*} (\mathbf{x}_0)\geq \mathcal{F}^{(t)}_\text{bddm}\left(\theta^*, \underset{\phi}{\text{argmin}} \mathcal{L}_\text{step}^{(s)}(\phi;\theta^{*})\right)\geq \mathcal{F}^{(t)}_\text{elbo}(\theta^*):=\mathbb{KL}\left(q_{\boldsymbol\beta}(\mathbf{x}_{t-1}|\mathbf{x}_{t}, \mathbf{x}_{0})||p_{\theta^*}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\right)$. We dropped the common entropy term $\mathbb{E}\left[\log p_\theta(\mathbf{x}_0|\mathbf{x}_1)\right] < 0$ to mainly compare the KL terms, therefore the lower bound might be positive. 
          </tr>
        </tbody>
      </table>
      <h3>
        Fast and high-fidelity speech generation using BDDMs:
      </h3>
      <p>
        By introducing a scheduling network optimized with our derived loss, we can generate high-fidelity speech with as few as 3 steps.
         <!-- style="background-color: #FFFF00" -->
      </p>
      <p>
	Text: <span class="text_e2e">Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition.</span>
      </p>
      <!-- WaveGrad outputs with <i>6 refinement steps:</i>      -->
      <p style="color:red;"><b></b></p>
      <table>
        <tbody>
          <tr>
            <td nowrap><b>Step 0 (White Noise):</b> </td><td style="text-align:center" nowrap> Note: Consider lower volume before listening</td>
          </tr>
          <tr>
            <td>
               <audio controls="">
                  <source src="wavs/rand.wav">
               </audio>
            </td>
            <td>
               <img src="imgs/noise_spec.png">
            </td>
          </tr>
          <tr>
            <td nowrap><b>Step 1:</b> </td><td style="text-align:center" nowrap></td>
          </tr>
          <tr>
            <td>
               <audio controls="">
                  <source src="wavs/s1.wav">
               </audio>
            </td>
            <td>
               <img src="imgs/spec1.png">
            </td>
          </tr>
          <tr>
            <td nowrap><b>Step 2:</b> </td><td style="text-align:center" nowrap></td>
          </tr>
          <tr>
            <td>
               <audio controls="">
                  <source src="wavs/s2.wav">
               </audio>
            </td>
            <td>
               <img src="imgs/spec2.png">
            </td>
          </tr>
          <tr>
            <td nowrap><b>Step 3:</b> </td><td style="text-align:center" nowrap></td>
          </tr>
          <tr>
            <td>
               <audio controls="">
                  <source src="wavs/s3.wav">
               </audio>
            </td>
            <td>
               <img src="imgs/spec3.png">
            </td>
          </tr>
        </tbody>
      </table>
         <h3> LJ speech samples from different generative diffusion models:</h3>
         <p>
            <b>Note:</b>
            Different rows correspond to different noise schedules or sampling methods for inference.
         </p>
         <table>
            <tbody>
               <tr>
                  <td nowrap> Text </td>
                  <td><span class="text_e2e">and having, quote, somewhat bushy, end quote, hair.</span></td>
                  <td><span class="text_e2e">since a disclosure of such detailed information relating to protective measures might undermine present methods of protecting the President.</span></td>
                  <td><span class="text_e2e" style="color:white">since a disclosure of such detailed information relating to protective measures might undermine present methods of protecting the President.</span></td>
               </tr>
               <tr>
                  <td nowrap>Ground Truth</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/GT_3.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/GT_4.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>DDPM - 8 steps (Grid Search)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_8_3.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_8_4.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>DDPM - 1000 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_1000_3.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_1000_4.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>DDIM - 8 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_8_3.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_8_4.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>DDIM - 100 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_100_3.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_100_4.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>NE - 8 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/NE_8_3.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/NE_8_4.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap><b>BDDM - 8 steps</b></td>
                  <td>
                     <audio controls="">
                        <source src="wavs/BDDM_8_3.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/BDDM_8_4.wav">
                     </audio>
                  </td>
               </tr>
            </tbody>
         </table>
         <h3> VCTK samples from different generative diffusion models:</h3>
         <p>
            <b>Note:</b>
            Different rows correspond to different noise schedules or sampling methods for inference.
         </p>
         <table>
            <tbody>
               <tr>
                  <td nowrap> Text </td>
                  <td><span class="text_e2e">Frankly, we should all have such problems.</span></td>
                  <td><span class="text_e2e">I felt he was excellent.</span></td>
                  <td><span class="text_e2e" style="color:white">Frankly, we should all have such problems.</span></td>
               </tr>
               <tr>
                  <td nowrap>Ground Truth</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/GT_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/GT_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>DDPM - 8 steps (Grid Search)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_8_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_8_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>DDPM - 1000 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_1000_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDPM_1000_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>DDIM - 8 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_8_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_8_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>DDIM - 100 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_100_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/DDIM_100_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap>NE - 8 steps (Linear)</td>
                  <td>
                     <audio controls="">
                        <source src="wavs/NE_8_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/NE_8_2.wav">
                     </audio>
                  </td>
               </tr>
               <tr>
                  <td nowrap><b>BDDM - 8 steps</b></td>
                  <td>
                     <audio controls="">
                        <source src="wavs/BDDM_8_1.wav">
                     </audio>
                  </td>
                  <td>
                     <audio controls="">
                        <source src="wavs/BDDM_8_2.wav">
                     </audio>
                  </td>
               </tr>
            </tbody>
         </table>
         <h3> CIFAR-10 samples generated from BDDM:</h3>
         <table>
        <tbody>
          <tr>
            <td> BDDM - 10 steps </td>
            <td> BDDM - 20 steps </td>
            <td> BDDM - 100 steps </td>
          </tr>
          <tr>
            <td> <img src="imgs/BDDM10.png" width="300px"> </td>
            <td> <img src="imgs/BDDM20.png" width="300px"> </td>
            <td> <img src="imgs/BDDM100.png" width="300px"> </td>
          </tr>
        </tbody>
      </table>
      </div>
   </body>
</html>
